{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning Methods: Part II, Spring 2021\n",
    "\n",
    "# Lab 1: Stats Review and Plotting\n",
    "\n",
    "**About This Lab**\n",
    "* We will be running through this notebook together. If you have a clarifying question or other question of broad interest, feel free to interrupt or use a pause to unmute and ask it! If you have a question that may result in a one-on-one breakout room (think: detailed inquiry, conceptual question, or help debugging), please ask it in the chat!\n",
    "* We recognize learning Python via Zoom comes with its challenges and that there are many modes of learning. Please go with what works best for you. That might be printing out the Jupyter notebook, duplicating it such that you can refer to the original, working directly in it. Up to you! There isn't a single right way.\n",
    "* This lab requires that you download the following file and place it in the same directory as this Jupyter notebook:\n",
    "    * `property_data.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "By the end of this lab, you will have reviewed how to:\n",
    "1. Read and write files\n",
    "2. Check for and drop nulls\n",
    "3. Export data\n",
    "4. Create subdataframes\n",
    "5. Produce descriptive statistics\n",
    "6. Conduct statistical tests\n",
    "\n",
    "You will also learn how to:\n",
    "1. Check for outliers \n",
    "2. Define a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib as mpl, math\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import t, chisquare, iqr\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install researchpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import researchpy as rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath for csv == 'Lab Data/property_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Connect to and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('Data/property_data.csv')\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert id variable type\n",
    "raw['id'] = raw['id'].astype(str)\n",
    "raw.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Drop nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many observations would be dropped?\n",
    "null_values = raw.isnull().sum(axis = 1)\n",
    "\n",
    "num_obs = len(raw[null_values>0])\n",
    "\n",
    "print(num_obs, len(raw))\n",
    "raw[null_values>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN values\n",
    "df = raw.dropna().reset_index(drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Check for outliers\n",
    "Plus a sneak preview of plots!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Data/boxplots.jpg' width = 500>\n",
    "Source: https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize population density\n",
    "x = df['pop_dens']\n",
    "plt.boxplot(x)\n",
    "plt.show()\n",
    "plt.hist(x, 250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many observations would be dropped if we got rid of 'price_000' outliers?\n",
    "# step 1: calculate interquartile range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: use the 1.5xIQR rule "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Export clean data (for future labs)\n",
    "Name it whatever you'd like and remeber where you save it so you can access next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_property_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Create sub-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[['house','apt','price_000','age_0_10','age_20_more','pcn_green','num_room']].copy()\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename variables of interest\n",
    "sub_df.rename(columns={\"price_000\":\"price\", \n",
    "                   \"age_0_10\":\"age_new\", \n",
    "                   \"age_20_more\":\"age_old\", \n",
    "                   \"num_room\":\"rooms\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Describe variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Continuous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# descriptive stats for property price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we're only interested in certain statistics, we can also call them up specifically \n",
    "# print the median and interquartile range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the median is equal to the 50% percentile above and IQR is equal to the 75th percentile minus the 25th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next week we'll learn how to use a histogram to visualize the distribution of a continous variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Discrete numeric variable (dummy variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive stats for house dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use the value_counts function (in general, it gives us a better sense of categorical variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we can normalize value_counts to get percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Define a function\n",
    "\n",
    "A function is a block of reusable code used to perform a single action that only runs when called. Python has many built in functions (like 'print') but you can also create your own.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if we want to see counts and percentages together, we can concatenate these outputs into one table\n",
    "\n",
    "# defining a function called 'tab' that can take in any dataframe and any variable and return the output below\n",
    "\n",
    "def tab(df, x):\n",
    "    \"\"\"This function concatenates the counts and percentages for a single variable in a dataframe.\"\"\"\n",
    "    \n",
    "    print (\"Total Count\", df[x].count())\n",
    "    print (\"Total Pct\", sum(df[x].value_counts(normalize=True)))\n",
    "    \n",
    "    return pd.concat([ df[x].value_counts(), df[x].value_counts(normalize=True) ], \n",
    "                     axis=1, keys=('counts','pct'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function\n",
    "tab(sub_df, 'house')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what steps could you take to apply this function to a different dataframe? \n",
    "# (hint: df in the function, and df at the where we call it with 'house' aren't the same thing...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Stats for all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions have been helpful for individual variables, but say you want to see summary stats for ALL the \n",
    "# variables in your dataframe at once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to see summary statistics like this for just a few variables, see the appendix code at the bottom!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define universal set of statistics to be called with \".agg\" command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 T-test (of means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Do apartments have different prices from houses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive price stats for apartment dv \n",
    "# groupby and aggregate functions are helpful for looking at crosstabulated summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create apt and non-apt price variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you wanted to normalize the price of a property by the number of bedrooms, how would you change the code? \n",
    "# (hint: more than one right answer!!)\n",
    "\n",
    "# create per room price variable in dataframe\n",
    "sub_df['pp_rm'] = sub_df['price']/df['rooms']\n",
    "\n",
    "# create variables for t-test\n",
    "apt_rm_p = sub_df[df.apt == 1].pp_rm #Apartment Price per Room\n",
    "n_apt_rm_p = sub_df[df.apt == 0].pp_rm #Non-Apartment Price per Room\n",
    "\n",
    "# run t-test\n",
    "ttest_ind(apt_rm_p, n_apt_rm_p, equal_var = False, nan_policy=\"omit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also run t-test with researchpy if that's your preference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Is the price of newer apartments different from older apartments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what descriptive stats are relevant here? \n",
    "# create subdataframe, group price of apartments by new vs. old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create old and new apartment price variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Chi-square test (of proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Are houses more likely to be older (age_20_more) or younger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive stats (crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize by row ('index') - could also normalize by 'columns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run chi-square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix A - Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing null values in order\n",
    "# will only show null counts for rows that have more than 0 null values\n",
    "\n",
    "### define the function\n",
    "def var_nulls (df):\n",
    "    null_counts = df.isnull().sum() #sum of null counts attributed to a variable\n",
    "    return null_counts[null_counts > 0].sort_values(ascending=False) #sort values greater than 0 largest to smallest\n",
    "\n",
    "### call the function\n",
    "var_nulls(raw)\n",
    "\n",
    "# output shows blank list because we have no null values here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counts - see counts and percentages together\n",
    "\n",
    "### define the function\n",
    "def tab(df, x):\n",
    "    print (\"Total Count\", df[x].count())\n",
    "    print (\"Total Pct\", sum(df[x].value_counts(normalize=True)))\n",
    "    return pd.concat([df[x].value_counts(), df[x].value_counts(normalize=True)], \n",
    "                     axis=1, keys=('counts','pct'))\n",
    "\n",
    "### call the function\n",
    "tab(sub_df, 'house') #specify the dataframe and the variable in the parentheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we used the groupby function before each statistical test we used - we can also call this up with one function!\n",
    "\n",
    "### define the function\n",
    "def grpby_stats (df, var1, var2):\n",
    "    stat = ['count', 'mean', 'min', 'max', 'median', 'std'] #specify the statistics we want\n",
    "    return df[var1].groupby(df[var2]).agg(stat) #group the first variable by the second variable, and aggregate stats\n",
    "\n",
    "### call the function\n",
    "grpby_stats(sub_df, 'price', 'apt') #specify the dataframe, key variabe, and grouping variable in the parentheses\n",
    "\n",
    "# does this work for the test in 4.1.2, where we define apt_p = (sub_df[sub_df.apt == 1].price)? try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to see this for ALL the variables in your dataframe, you use this code.\n",
    "# this asks Python to describe the entire dataframe, and transpose (T) the columns and rows\n",
    "# try deleting the .T to see what happens if you don't use it - either way is fine!\n",
    "\n",
    "sub_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if you just want to view a few of your key variables of interest?\n",
    "\n",
    "# list of key variables\n",
    "key_var = ['apt','price','rooms']\n",
    "\n",
    "# code calling a few variables \n",
    "sub_df[key_var].describe().T\n",
    "\n",
    "# you could also use this code below if you don't want to separately define a list of variables: \n",
    "sub_df[['apt','price','rooms']].describe().T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
